{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MMjHsM9TSmW"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49VIe1sP2LmK"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXEhB-oDxf-p"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yrm7XFBxebN"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, path, transform):\n",
        "        super().__init__()\n",
        "        self.path = Path(path)\n",
        "        self.transform = transform\n",
        "        self.data = list(self.path.rglob(pattern='*.*'))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = Image.open(fp=self.data[index]).convert(mode=\"RGB\")\n",
        "        return self.transform(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zyQLQwhs7EV"
      },
      "outputs": [],
      "source": [
        "class CustomDataModule(L.LightningDataModule):\n",
        "    def __init__(self, train_dir, valid_dir, infer_dir, bench_dir, transform, batch_size=32, num_workers=4):\n",
        "        super().__init__()\n",
        "        self.train_dir = Path(train_dir)\n",
        "        self.valid_dir = Path(valid_dir)\n",
        "        self.infer_dir = Path(infer_dir)\n",
        "        self.bench_dir = Path(bench_dir)\n",
        "\n",
        "        self.transform = transform\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_datasets = self._set_dataset(path=self.train_dir)\n",
        "        self.valid_datasets = self._set_dataset(path=self.valid_dir)\n",
        "        self.bench_datasets = self._set_dataset(path=self.bench_dir)\n",
        "        self.infer_datasets = self._set_dataset(path=self.infer_dir)\n",
        "\n",
        "    def _set_dataset(self, path):\n",
        "        datasets = []\n",
        "        for folder in path.iterdir():\n",
        "            if folder.is_dir():\n",
        "                datasets.append(\n",
        "                    CustomDataset(\n",
        "                        path=folder,\n",
        "                        transform=self.transform\n",
        "                    )\n",
        "                )\n",
        "        return datasets\n",
        "\n",
        "    def _set_dataloader(self, datasets, concat=False, shuffle=False):\n",
        "        if concat:\n",
        "            dataloader = DataLoader(\n",
        "                dataset=ConcatDataset(datasets=datasets),\n",
        "                batch_size=self.batch_size,\n",
        "                shuffle=shuffle,\n",
        "                num_workers=self.num_workers,\n",
        "                pin_memory=True\n",
        "            )\n",
        "            return dataloader\n",
        "        else:\n",
        "            dataloaders = []\n",
        "            for dataset in datasets:\n",
        "                loader = DataLoader(\n",
        "                    dataset=dataset,\n",
        "                    batch_size=self.batch_size,\n",
        "                    shuffle=shuffle,\n",
        "                    num_workers=self.num_workers,\n",
        "                    pin_memory=True\n",
        "                )\n",
        "                dataloaders.append(loader)\n",
        "            return dataloaders\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self._set_dataloader(datasets=self.train_datasets, concat=True, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self._set_dataloader(datasets=self.valid_datasets, concat=True)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self._set_dataloader(datasets=self.bench_datasets)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        return self._set_dataloader(datasets=self.infer_datasets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-ofYHcU2P4U"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uohVFoIuyKbK"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yz-ob2QEyGx-"
      },
      "outputs": [],
      "source": [
        "class DataTransform:\n",
        "    def __init__(self, image_size=256):\n",
        "        self.image_size = image_size\n",
        "\n",
        "        self.transform = self._build_transform()\n",
        "\n",
        "    def _build_transform(self):\n",
        "        base = [\n",
        "            transforms.Resize(size=(self.image_size, self.image_size)),\n",
        "            transforms.ToTensor(),\n",
        "        ]\n",
        "\n",
        "        return transforms.Compose(transforms=base)\n",
        "\n",
        "    def __call__(self, image):\n",
        "        return self.transform(img=image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from scipy.ndimage import convolve\n",
        "from scipy.special import gamma\n",
        "from torchmetrics.image import (\n",
        "    PeakSignalNoiseRatio,\n",
        "    StructuralSimilarityIndexMeasure,\n",
        "    LearnedPerceptualImagePatchSimilarity,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImageQualityMetrics(nn.Module):\n",
        "    def __init__(self, device=\"cuda\", data_range=1.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device_type = device\n",
        "\n",
        "        # reference-based metrics\n",
        "        self.psnr = PeakSignalNoiseRatio(\n",
        "            data_range=data_range).to(device=device)\n",
        "        self.ssim = StructuralSimilarityIndexMeasure(\n",
        "            data_range=data_range).to(device=device)\n",
        "        self.lpips = LearnedPerceptualImagePatchSimilarity(\n",
        "            net_type='squeeze').to(device=device)\n",
        "\n",
        "        # for NIQE (dummy pristine dist)\n",
        "        self.niqe_stats = np.load(\n",
        "            file=\"utils/files/niqe_params.npz\", allow_pickle=True)\n",
        "        self.mu_pris_param = self.niqe_stats['mu_pris_param']\n",
        "        self.cov_pris_param = self.niqe_stats['cov_pris_param']\n",
        "        self.gaussian_window = self.niqe_stats['gaussian_window']\n",
        "\n",
        "    def forward(self, preds: torch.Tensor, targets: torch.Tensor):\n",
        "        preds = preds.to(device=self.device_type)\n",
        "        targets = targets.to(device=self.device_type)\n",
        "\n",
        "        return {\n",
        "            \"PSNR\": self.psnr(preds, targets).item(),\n",
        "            \"SSIM\": self.ssim(preds, targets).item(),\n",
        "            \"LPIPS\": self.lpips(preds, targets).squeeze().mean().item(),\n",
        "        }\n",
        "\n",
        "    def no_ref(self, preds: torch.Tensor):\n",
        "        preds = preds.to(device=self.device_type)\n",
        "        preds_np = preds.detach().cpu().numpy()\n",
        "        preds_np = np.clip(a=preds_np, a_min=0, a_max=1)\n",
        "\n",
        "        niqe_list = []\n",
        "        brisque_list = []\n",
        "\n",
        "        for img in preds_np:\n",
        "            # (C, H, W) → (H, W, C)\n",
        "            img_np = np.transpose(a=img, axes=(1, 2, 0))\n",
        "            img_np_uint8 = (img_np * 255).astype(dtype=np.uint8)\n",
        "\n",
        "            niqe = self._compute_niqe(img_np=img_np)\n",
        "            brisuqe = self._compute_brisque(img=img_np_uint8)\n",
        "\n",
        "            niqe_list.append(niqe)\n",
        "            brisque_list.append(brisuqe)\n",
        "\n",
        "        return {\n",
        "            \"NIQE\": float(x=np.mean(a=niqe_list)),\n",
        "            \"BRISQUE\": float(x=np.mean(a=brisque_list)),\n",
        "        }\n",
        "\n",
        "    def full(self, preds, targets):\n",
        "        ref_metrics = self.forward(preds=preds, targets=targets)\n",
        "        no_ref_metrics = self.no_ref(preds=preds)\n",
        "        return {**ref_metrics, **no_ref_metrics}\n",
        "\n",
        "    # --------------------------\n",
        "    # Custom no-reference metrics\n",
        "    # --------------------------\n",
        "\n",
        "    def _compute_niqe(self, img_np):\n",
        "        img = img_np.astype(np.float32)\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        gray = gray.round()\n",
        "        return self._niqe(img=gray)\n",
        "\n",
        "    def _compute_brisque(self, img):\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        brisque_score = cv2.quality.QualityBRISQUE_compute(\n",
        "            img, \"utils/files/brisque_model.yaml\", \"utils/files/brisque_range.yaml\")\n",
        "        return brisque_score\n",
        "\n",
        "    def _niqe(self, img, block_size_h=96, block_size_w=96):\n",
        "        assert img.ndim == 2\n",
        "        h, w = img.shape\n",
        "        num_block_h = math.floor(h / block_size_h)\n",
        "        num_block_w = math.floor(w / block_size_w)\n",
        "        img = img[0:num_block_h * block_size_h, 0:num_block_w * block_size_w]\n",
        "\n",
        "        distparam = []\n",
        "        for scale in (1, 2):\n",
        "            mu = convolve(\n",
        "                input=img, weights=self.gaussian_window, mode='nearest')\n",
        "            sigma = np.sqrt(np.abs(convolve(\n",
        "                input=np.square(img), weights=self.gaussian_window, mode='nearest') - np.square(mu)))\n",
        "            img_nomalized = (img - mu) / (sigma + 1)\n",
        "\n",
        "            feat = []\n",
        "            for idx_w in range(num_block_w):\n",
        "                for idx_h in range(num_block_h):\n",
        "                    block = img_nomalized[\n",
        "                        idx_h * block_size_h // scale:(idx_h + 1) * block_size_h // scale,\n",
        "                        idx_w * block_size_w // scale:(idx_w + 1) * block_size_w // scale\n",
        "                    ]\n",
        "                    feat.append(self._compute_feature(block=block))\n",
        "\n",
        "            distparam.append(np.array(object=feat))\n",
        "\n",
        "            if scale == 1:\n",
        "                img = cv2.resize(img / 255., dsize=(0, 0), fx=0.5,\n",
        "                                 fy=0.5, interpolation=cv2.INTER_CUBIC) * 255.\n",
        "\n",
        "        distparam = np.concatenate(distparam, axis=1)\n",
        "        mu_distparam = np.nanmean(a=distparam, axis=0)\n",
        "        distparam_no_nan = distparam[~np.isnan(distparam).any(axis=1)]\n",
        "        cov_distparam = np.cov(m=distparam_no_nan, rowvar=False)\n",
        "\n",
        "        invcov_param = np.linalg.pinv(\n",
        "            (self.cov_pris_param + cov_distparam) / 2)\n",
        "        quality = np.matmul(\n",
        "            np.matmul((self.mu_pris_param - mu_distparam), invcov_param),\n",
        "            np.transpose(a=(self.mu_pris_param - mu_distparam))\n",
        "        )\n",
        "        return float(x=np.sqrt(quality))\n",
        "\n",
        "    def _compute_feature(self, block):\n",
        "        def estimate_aggd_param(block):\n",
        "            block = block.flatten()\n",
        "            gam = np.arange(start=0.2, stop=10.001, step=0.001)\n",
        "            gam_reciprocal = np.reciprocal(gam)\n",
        "            r_gam = np.square(gamma(gam_reciprocal * 2)) / (\n",
        "                gamma(gam_reciprocal) * gamma(gam_reciprocal * 3))\n",
        "\n",
        "            left_std = np.sqrt(np.mean(block[block < 0]**2))\n",
        "            right_std = np.sqrt(np.mean(block[block > 0]**2))\n",
        "            gammahat = left_std / right_std\n",
        "            rhat = (np.mean(np.abs(block)))**2 / np.mean(block**2)\n",
        "            rhatnorm = (rhat * (gammahat**3 + 1) *\n",
        "                        (gammahat + 1)) / ((gammahat**2 + 1)**2)\n",
        "            array_position = np.argmin(a=(r_gam - rhatnorm)**2)\n",
        "            alpha = gam[array_position]\n",
        "            beta_l = left_std * np.sqrt(gamma(1 / alpha) / gamma(3 / alpha))\n",
        "            beta_r = right_std * np.sqrt(gamma(1 / alpha) / gamma(3 / alpha))\n",
        "            return (alpha, beta_l, beta_r)\n",
        "\n",
        "        feat = []\n",
        "        alpha, beta_l, beta_r = estimate_aggd_param(block=block)\n",
        "        feat.extend([alpha, (beta_l + beta_r) / 2])\n",
        "        shifts = [[0, 1], [1, 0], [1, 1], [1, -1]]\n",
        "        for shift in shifts:\n",
        "            shifted = np.roll(a=block, shift=shift, axis=(0, 1))\n",
        "            alpha, beta_l, beta_r = estimate_aggd_param(block=block * shifted)\n",
        "            mean = (beta_r - beta_l) * (gamma(2 / alpha) / gamma(1 / alpha))\n",
        "            feat.extend([alpha, mean, beta_l, beta_r])\n",
        "        return feat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from torchvision.utils import save_image\n",
        "from torchinfo import summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_dirs(path: str | Path):\n",
        "    path = Path(path)\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "    return path\n",
        "\n",
        "\n",
        "def print_metrics(metrics: dict, prefix: str = \"\"):\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{prefix}{k}: {v:.4f}\")\n",
        "\n",
        "\n",
        "def save_images(results, save_dir, prefix=\"infer\", ext=\"png\"):\n",
        "    for i, datasets in enumerate(iterable=results):\n",
        "        save_path = make_dirs(path=f\"{save_dir}/batch{i+1}\")\n",
        "        for ii, batch in enumerate(iterable=datasets):\n",
        "            save_image(\n",
        "                tensor=batch,\n",
        "                fp=save_path / f\"{prefix}_{ii:04d}.{ext}\",\n",
        "                nrow=8,\n",
        "                padding=2,\n",
        "                normalize=True,\n",
        "                value_range=(0, 1)\n",
        "            )\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def summarize_model(model, input_size):\n",
        "    return summary(model=model, input_size=input_size, depth=3, col_names=[\"input_size\", \"output_size\", \"num_params\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lh4S0MOTaaJ"
      },
      "source": [
        "# Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA5HkZA-2VRM"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WA-AweC9yQbI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from lightning import Trainer, seed_everything\n",
        "from lightning.pytorch.callbacks import *\n",
        "from lightning.pytorch.loggers import TensorBoardLogger\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYf9FGjfyTUg"
      },
      "outputs": [],
      "source": [
        "class LightningTrainer:\n",
        "    def __init__(self, model, hparams: dict, ckpt: Path = None, transform=None):\n",
        "        self.hparams = hparams\n",
        "        self.transform = transform if transform else DataTransform()\n",
        "        seed_everything(seed=hparams[\"seed\"], workers=True)\n",
        "\n",
        "        # --- 모델 정의\n",
        "        if ckpt:\n",
        "            self.model = model.load_from_checkpoint(\n",
        "                checkpoint_path=ckpt,\n",
        "                map_location=\"cuda\",\n",
        "            )\n",
        "            self.ckpt = ckpt\n",
        "        else:\n",
        "            self.model = model\n",
        "\n",
        "        # --- DataModule 정의\n",
        "        self.datamodule = self._build_datamodule()\n",
        "\n",
        "        # --- 로깅 설정\n",
        "        self.logger = self._build_logger()\n",
        "\n",
        "        # --- 콜백 정의\n",
        "        self.callbacks = self._build_callbacks()\n",
        "\n",
        "        # --- Lightning Trainer 정의\n",
        "        self.trainer = Trainer(\n",
        "            max_epochs=hparams[\"epochs\"],\n",
        "            accelerator=\"gpu\",\n",
        "            devices=1,\n",
        "            precision=\"32\",\n",
        "            logger=self.logger,\n",
        "            callbacks=self.callbacks,\n",
        "            log_every_n_steps=5,\n",
        "        )\n",
        "\n",
        "    def _build_datamodule(self):\n",
        "        return CustomDataModule(\n",
        "            train_dir=self.hparams[\"train_data_path\"],\n",
        "            valid_dir=self.hparams[\"valid_data_path\"],\n",
        "            infer_dir=self.hparams[\"infer_data_path\"],\n",
        "            bench_dir=self.hparams[\"bench_data_path\"],\n",
        "            transform=DataTransform(image_size=self.hparams[\"image_size\"]),\n",
        "            batch_size=self.hparams[\"batch_size\"],\n",
        "            num_workers=int(os.cpu_count() * 0.9),\n",
        "        )\n",
        "\n",
        "    def _build_logger(self):\n",
        "        return TensorBoardLogger(\n",
        "            save_dir=self.hparams[\"log_dir\"],\n",
        "            name=self.hparams[\"experiment_name\"]\n",
        "        )\n",
        "\n",
        "    def _build_callbacks(self):\n",
        "        return [\n",
        "            ModelCheckpoint(\n",
        "                monitor=\"valid/4_tot\",\n",
        "                save_top_k=1,\n",
        "                mode=\"min\",\n",
        "                filename=\"best-{epoch:02d}\",\n",
        "            ),\n",
        "            ModelCheckpoint(\n",
        "                every_n_epochs=1,\n",
        "                save_top_k=-1,  # 모두 저장\n",
        "                filename=\"epoch-{epoch:02d}\",\n",
        "            ),\n",
        "            EarlyStopping(\n",
        "                monitor=\"valid/4_tot\",\n",
        "                patience=4,\n",
        "                mode=\"min\",\n",
        "                verbose=True,\n",
        "            ),\n",
        "            LearningRateMonitor(logging_interval=\"step\"),\n",
        "            RichProgressBar(),\n",
        "        ]\n",
        "\n",
        "    def run(self):\n",
        "        print(\"[INFO] Start Training...\")\n",
        "        self.trainer.fit(\n",
        "            model=self.model,\n",
        "            datamodule=self.datamodule\n",
        "        )\n",
        "        print(\"[INFO] Training Completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN4DsMQS2bfB"
      },
      "source": [
        "## Validater"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TcPiApZ1EBm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from lightning import Trainer\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lxZzwSb0oM3"
      },
      "outputs": [],
      "source": [
        "class LightningValidater:\n",
        "    def __init__(self, model, trainer: Trainer, ckpt: Path, hparams: dict):\n",
        "        self.hparams = hparams\n",
        "\n",
        "        # --- 모델 정의\n",
        "        if ckpt:\n",
        "            self.model = model.load_from_checkpoint(\n",
        "                checkpoint_path=ckpt,\n",
        "                map_location=\"cuda\",\n",
        "            )\n",
        "            self.ckpt = ckpt\n",
        "        else:\n",
        "            self.model = model\n",
        "            self.ckpt = \"best\"\n",
        "\n",
        "        # --- Lightning Trainer 정의\n",
        "        self.trainer = trainer\n",
        "\n",
        "        # --- DataModule 정의\n",
        "        self.datamodule = self._build_datamodule()\n",
        "\n",
        "    def _build_datamodule(self):\n",
        "        return CustomDataModule(\n",
        "            train_dir=self.hparams[\"train_data_path\"],\n",
        "            valid_dir=self.hparams[\"valid_data_path\"],\n",
        "            infer_dir=self.hparams[\"infer_data_path\"],\n",
        "            bench_dir=self.hparams[\"bench_data_path\"],\n",
        "            transform=DataTransform(image_size=self.hparams[\"image_size\"]),\n",
        "            batch_size=self.hparams[\"batch_size\"],\n",
        "            num_workers=int(os.cpu_count() * 0.9),\n",
        "        )\n",
        "\n",
        "    def run(self):\n",
        "        print(\"[INFO] Start Validating...\")\n",
        "        results = self.trainer.validate(\n",
        "            model=self.model,\n",
        "            datamodule=self.datamodule,\n",
        "            ckpt_path=self.ckpt\n",
        "        )\n",
        "        print(\"[VALIDATION RESULT]\")\n",
        "        for res in tqdm(results):\n",
        "            print(res)\n",
        "\n",
        "        print(\"[INFO] Validation Completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-XEQ7Ab2g_L"
      },
      "source": [
        "## Inferencer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_fzZBK51Hi5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "\n",
        "from lightning import Trainer\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Smv5YDwQ1I0U"
      },
      "outputs": [],
      "source": [
        "class LightningInferencer:\n",
        "    def __init__(self, model, trainer: Trainer, ckpt: Path, hparams: Path):\n",
        "        with open(file=hparams) as f:\n",
        "            hparams = yaml.load(stream=f, Loader=yaml.FullLoader)\n",
        "        self.hparams = hparams\n",
        "\n",
        "        if ckpt:\n",
        "            self.model = model.load_from_checkpoint(\n",
        "                checkpoint_path=str(object=ckpt),\n",
        "                map_location=\"cuda\",\n",
        "            )\n",
        "            self.ckpt = ckpt\n",
        "        else:\n",
        "            self.model = model\n",
        "            self.ckpt = \"best\"\n",
        "\n",
        "        # --- Lightning Trainer 정의\n",
        "        self.trainer = trainer\n",
        "\n",
        "        # --- DataModule 정의\n",
        "        self.datamodule = self._build_datamodule()\n",
        "\n",
        "        self.save_dir = ckpt.parents[1] / hparams[\"inference\"]\n",
        "        print(f\"save_dir: {self.save_dir}\")\n",
        "\n",
        "    def _build_datamodule(self):\n",
        "        return CustomDataModule(\n",
        "            train_dir=self.hparams[\"train_data_path\"],\n",
        "            valid_dir=self.hparams[\"valid_data_path\"],\n",
        "            infer_dir=self.hparams[\"infer_data_path\"],\n",
        "            bench_dir=self.hparams[\"bench_data_path\"],\n",
        "            transform=DataTransform(image_size=self.hparams[\"image_size\"]),\n",
        "            batch_size=self.hparams[\"batch_size\"],\n",
        "            num_workers=int(os.cpu_count() * 0.9),\n",
        "        )\n",
        "\n",
        "    def run(self):\n",
        "        print(\"[INFO] Start Inferencing...\")\n",
        "        results = self.trainer.predict(\n",
        "            model=self.model,\n",
        "            datamodule=self.datamodule,\n",
        "            ckpt_path=self.ckpt\n",
        "        )\n",
        "        save_images(results=results, save_dir=self.save_dir)\n",
        "        print(\"[INFO] Inference Completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YobhDE1g2lC3"
      },
      "source": [
        "## Benchmarker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_f7eA4M1P8Y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from lightning import Trainer\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCpVMRNi1Sjx"
      },
      "outputs": [],
      "source": [
        "class LightningBenchmarker:\n",
        "    def __init__(self, model, trainer: Trainer, ckpt: Path, hparams: dict):\n",
        "        self.hparams = hparams\n",
        "\n",
        "        if ckpt:\n",
        "            self.model = model.load_from_checkpoint(\n",
        "                checkpoint_path=ckpt,\n",
        "                map_location=\"cuda\",\n",
        "            )\n",
        "            self.ckpt = ckpt\n",
        "        else:\n",
        "            self.model = model\n",
        "            self.ckpt = \"best\"\n",
        "\n",
        "        # --- Lightning Trainer 정의\n",
        "        self.trainer = trainer\n",
        "\n",
        "        # --- DataModule 정의\n",
        "        self.datamodule = self._build_datamodule()\n",
        "\n",
        "        self.save_dir = ckpt.parents[1] / hparams[\"benchmark\"]\n",
        "        print(f\"save_dir: {self.save_dir}\")\n",
        "\n",
        "        # --- 평가 메트릭 정의\n",
        "        self.metric = ImageQualityMetrics(device=\"cuda\")\n",
        "        self.metric.eval()\n",
        "\n",
        "    def _build_datamodule(self):\n",
        "        datamodule = CustomDataModule(\n",
        "            train_dir=self.hparams[\"train_data_path\"],\n",
        "            valid_dir=self.hparams[\"valid_data_path\"],\n",
        "            infer_dir=self.hparams[\"infer_data_path\"],\n",
        "            bench_dir=self.hparams[\"bench_data_path\"],\n",
        "            transform=DataTransform(image_size=self.hparams[\"image_size\"]),\n",
        "            batch_size=self.hparams[\"batch_size\"],\n",
        "            num_workers=int(os.cpu_count() * 0.9),\n",
        "        )\n",
        "        datamodule.setup()  # 벤치마크 데이터셋 사용 위해 미리 세팅\n",
        "        return datamodule\n",
        "\n",
        "    def run(self):\n",
        "        print(\"[INFO] Start benchmarking\")\n",
        "\n",
        "        results = self.trainer.test(\n",
        "            model=self.model,\n",
        "            datamodule=self.datamodule,\n",
        "            ckpt_path=self.ckpt\n",
        "        )\n",
        "        print(\"results\", results)\n",
        "        print(\"\\n[FINAL BENCHMARK RESULT]\")\n",
        "        for i, datasets in tqdm(enumerate(iterable=results)):\n",
        "            for k, v in datasets.items():\n",
        "                print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "        save_images(results=results, save_dir=self.save_dir)\n",
        "        print(\"[INFO] Benchmark Completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QFt6KdDTjPW"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class L_col(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean_rgb = torch.mean(\n",
        "            input=x,\n",
        "            dim=[2, 3],\n",
        "            keepdim=True\n",
        "        )\n",
        "        mr, mg, mb = torch.split(\n",
        "            tensor=mean_rgb,\n",
        "            split_size_or_sections=1,\n",
        "            dim=1\n",
        "        )\n",
        "\n",
        "        Drg = torch.pow(input=mr - mg, exponent=2)\n",
        "        Drb = torch.pow(input=mr - mb, exponent=2)\n",
        "        Dgb = torch.pow(input=mb - mg, exponent=2)\n",
        "\n",
        "        c = torch.pow(\n",
        "            input=torch.pow(input=Drg, exponent=2) +\n",
        "            torch.pow(input=Drb, exponent=2) +\n",
        "            torch.pow(input=Dgb, exponent=2),\n",
        "            exponent=0.5\n",
        "        )\n",
        "        return c\n",
        "\n",
        "\n",
        "class L_spa(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        kernel_l = torch.FloatTensor([\n",
        "            [0, 0, 0],\n",
        "            [-1, 1, 0],\n",
        "            [0, 0, 0]\n",
        "        ]).cuda().unsqueeze(dim=0).unsqueeze(dim=0)\n",
        "        kernel_r = torch.FloatTensor([\n",
        "            [0, 0, 0],\n",
        "            [0, 1, -1],\n",
        "            [0, 0, 0]\n",
        "        ]).cuda().unsqueeze(dim=0).unsqueeze(dim=0)\n",
        "        kernel_u = torch.FloatTensor([\n",
        "            [0, -1, 0],\n",
        "            [0, 1, 0],\n",
        "            [0, 0, 0]\n",
        "        ]).cuda().unsqueeze(dim=0).unsqueeze(dim=0)\n",
        "        kernel_d = torch.FloatTensor([\n",
        "            [0, 0, 0],\n",
        "            [0, 1, 0],\n",
        "            [0, -1, 0]\n",
        "        ]).cuda().unsqueeze(dim=0).unsqueeze(dim=0)\n",
        "\n",
        "        self.weight_l = nn.Parameter(data=kernel_l, requires_grad=False)\n",
        "        self.weight_r = nn.Parameter(data=kernel_r, requires_grad=False)\n",
        "        self.weight_u = nn.Parameter(data=kernel_u, requires_grad=False)\n",
        "        self.weight_d = nn.Parameter(data=kernel_d, requires_grad=False)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=4)\n",
        "\n",
        "    def forward(self, org, enh):\n",
        "        org_mean = torch.mean(input=org, dim=1, keepdim=True)\n",
        "        enh_mean = torch.mean(input=enh, dim=1, keepdim=True)\n",
        "\n",
        "        org_pool = self.pool(org_mean)\n",
        "        enh_pool = self.pool(enh_mean)\n",
        "\n",
        "        D_org_l = F.conv2d(input=org_pool, weight=self.weight_l, padding=1)\n",
        "        D_org_r = F.conv2d(input=org_pool, weight=self.weight_r, padding=1)\n",
        "        D_org_u = F.conv2d(input=org_pool, weight=self.weight_u, padding=1)\n",
        "        D_org_d = F.conv2d(input=org_pool, weight=self.weight_d, padding=1)\n",
        "\n",
        "        D_enh_l = F.conv2d(input=enh_pool, weight=self.weight_l, padding=1)\n",
        "        D_enh_r = F.conv2d(input=enh_pool, weight=self.weight_r, padding=1)\n",
        "        D_enh_u = F.conv2d(input=enh_pool, weight=self.weight_u, padding=1)\n",
        "        D_enh_d = F.conv2d(input=enh_pool, weight=self.weight_d, padding=1)\n",
        "\n",
        "        D_l = torch.pow(input=D_org_l - D_enh_l, exponent=2)\n",
        "        D_r = torch.pow(input=D_org_r - D_enh_r, exponent=2)\n",
        "        D_u = torch.pow(input=D_org_u - D_enh_u, exponent=2)\n",
        "        D_d = torch.pow(input=D_org_d - D_enh_d, exponent=2)\n",
        "\n",
        "        s = (D_l + D_r + D_u + D_d)\n",
        "        return s\n",
        "\n",
        "\n",
        "class L_exp(nn.Module):\n",
        "    def __init__(self, patch_size=16, mean_val=0.8):\n",
        "        super().__init__()\n",
        "        self.pool = nn.AvgPool2d(kernel_size=patch_size)\n",
        "        self.mean_val = mean_val\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.mean(input=x, dim=1, keepdim=True)\n",
        "        mean = self.pool(x)\n",
        "\n",
        "        e = torch.mean(\n",
        "            input=torch.pow(\n",
        "                input=mean - torch.FloatTensor(\n",
        "                    [self.mean_val]\n",
        "                ).cuda(),\n",
        "                exponent=2\n",
        "            )\n",
        "        )\n",
        "        return e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQXFZQKy2pao"
      },
      "source": [
        "## Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV7wTXp52sq_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksWXAbzx25Pc"
      },
      "outputs": [],
      "source": [
        "class RGB2YCrCb(nn.Module):\n",
        "    def __init__(self, offset=0.5):\n",
        "        super().__init__()\n",
        "        self.offset = offset\n",
        "        self.register_buffer(\n",
        "            name='weights',\n",
        "            tensor=torch.tensor(\n",
        "                data=[\n",
        "                    [0.299,  0.587,  0.114],   # Y\n",
        "                    [0.713, -0.713,  0.000],   # Cr\n",
        "                    [0.000, -0.564,  0.564],   # Cb\n",
        "                ],\n",
        "                dtype=torch.float32\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.einsum('bchw,oc->bohw', x, self.weights)\n",
        "\n",
        "        Y = out[:, 0:1, :, :]  # (B,1,H,W)\n",
        "        Cr = out[:, 1:2, :, :] + self.offset  # (B,1,H,W)\n",
        "        Cb = out[:, 2:3, :, :] + self.offset  # (B,1,H,W)\n",
        "        return Y, Cr, Cb\n",
        "\n",
        "\n",
        "class YCrCb2RGB(nn.Module):\n",
        "    def __init__(self, offset=0.5,):\n",
        "        super().__init__()\n",
        "        self.offset = offset\n",
        "        self.register_buffer(\n",
        "            name='weights',\n",
        "            tensor=torch.tensor(\n",
        "                data=[\n",
        "                    [1.000, 1.403, 0.000],\n",
        "                    [1.000, -0.714, -0.344],\n",
        "                    [1.000, 0.000, 1.773]\n",
        "                ],\n",
        "                dtype=torch.float32\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def forward(self, Y, Cr, Cb):\n",
        "        Cr = Cr - self.offset\n",
        "        Cb = Cb - self.offset\n",
        "\n",
        "        inputs = torch.cat(tensors=[Y, Cr, Cb], dim=1)  # (B,3,H,W)\n",
        "\n",
        "        x = torch.einsum('bchw,oc->bohw', inputs, self.weights)\n",
        "        return x\n",
        "\n",
        "\n",
        "class HomomorphicSeparation(nn.Module):\n",
        "    def __init__(self, size=256, init_cutoff=0.1, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.eps = eps\n",
        "\n",
        "        init_p = float(init_cutoff)\n",
        "        raw_init = torch.log(input=torch.tensor(data=init_p / (1.0 - init_p)))\n",
        "        self.raw_cutoff = nn.Parameter(data=raw_init)\n",
        "\n",
        "        coord = torch.linspace(start=-1, end=1, steps=size)\n",
        "        y, x = torch.meshgrid(coord, coord, indexing='ij')\n",
        "        d = torch.sqrt(input=x**2 + y**2)  # (H, W)\n",
        "        self.register_buffer(name='d', tensor=d)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        cutoff = torch.sigmoid(input=self.raw_cutoff)\n",
        "\n",
        "        mask2d = torch.exp(input=-(self.d ** 2) / (2 * (cutoff ** 2)))\n",
        "        mask = mask2d.unsqueeze(dim=0).expand(B, H, W)\n",
        "\n",
        "        # 1. log 변환\n",
        "        x_log = torch.log(input=x + self.eps).squeeze(dim=1)    # (B, 1, H, W)\n",
        "\n",
        "        # 2. FFT\n",
        "        x_fft = torch.fft.fft2(x_log)  # (B, H, W)\n",
        "\n",
        "        # 3. Low-pass / High-pass 분리\n",
        "        low_fft = x_fft * mask\n",
        "        high_fft = x_fft * (1 - mask)\n",
        "\n",
        "        # 4. IFFT 후 real 값 추출\n",
        "        low_spatial = torch.real(\n",
        "            input=torch.fft.ifft2(\n",
        "                low_fft\n",
        "            )\n",
        "        )  # (B,1,H,W)\n",
        "        high_spatial = torch.real(\n",
        "            input=torch.fft.ifft2(\n",
        "                high_fft\n",
        "            )\n",
        "        )  # (B,1,H,W)\n",
        "\n",
        "        # 5. exp 복원\n",
        "        illumination = torch.exp(input=low_spatial).unsqueeze(dim=1)\n",
        "        detail = torch.exp(input=high_spatial).unsqueeze(dim=1)\n",
        "\n",
        "        return illumination, detail\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.in_channels,\n",
        "                out_channels=self.out_channels,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=out_channels),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.out_channels,\n",
        "                out_channels=self.out_channels,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=out_channels),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout2d(p=0.2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(\n",
        "                kernel_size=2\n",
        "            ),\n",
        "            DoubleConv(\n",
        "                in_channels=self.in_channels,\n",
        "                out_channels=self.out_channels,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.up = nn.ConvTranspose2d(\n",
        "            in_channels=self.in_channels,\n",
        "            out_channels=self.out_channels,\n",
        "            kernel_size=2, stride=2\n",
        "        )\n",
        "\n",
        "        self.conv = DoubleConv(\n",
        "            in_channels=self.in_channels,\n",
        "            out_channels=self.out_channels\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(\n",
        "            input=x1,\n",
        "            pad=[\n",
        "                diffX // 2, diffX - diffX // 2,\n",
        "                diffY // 2, diffY - diffY // 2\n",
        "            ]\n",
        "        )\n",
        "        x = torch.cat(tensors=[x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.inc = DoubleConv(in_channels=self.in_channels, out_channels=64)\n",
        "        self.down1 = Down(in_channels=64, out_channels=128)\n",
        "        self.down2 = Down(in_channels=128, out_channels=256)\n",
        "        self.down3 = Down(in_channels=256, out_channels=512)\n",
        "        self.down4 = Down(in_channels=512, out_channels=1024)\n",
        "        self.up1 = Up(in_channels=1024, out_channels=512)\n",
        "        self.up2 = Up(in_channels=512, out_channels=256)\n",
        "        self.up3 = Up(in_channels=256, out_channels=128)\n",
        "        self.up4 = Up(in_channels=128, out_channels=64)\n",
        "        self.outc = self.outc = nn.Sequential(\n",
        "            DoubleConv(in_channels=64, out_channels=64),\n",
        "            nn.Conv2d(in_channels=64, out_channels=out_channels, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_i = self.inc(x)           # 64\n",
        "        d_1 = self.down1(x_i)       # 128\n",
        "        d_2 = self.down2(d_1)       # 256\n",
        "        d_3 = self.down3(d_2)       # 512\n",
        "        d_4 = self.down4(d_3)       # 1024\n",
        "        u_4 = self.up1(d_4, d_3)    # 512\n",
        "        u_3 = self.up2(u_4, d_2)    # 256\n",
        "        u_2 = self.up3(u_3, d_1)    # 128\n",
        "        u_1 = self.up4(u_2, x_i)    # 64\n",
        "        x_o = self.outc(u_1)\n",
        "        return x_o\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResidualConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.in_channels,\n",
        "                out_channels=self.out_channels,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=out_channels),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.out_channels,\n",
        "                out_channels=self.out_channels,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=out_channels),\n",
        "        )\n",
        "\n",
        "        if self.in_channels != self.out_channels:\n",
        "            self.residual_conv = nn.Conv2d(\n",
        "                in_channels=self.in_channels,\n",
        "                out_channels=self.out_channels,\n",
        "                kernel_size=1\n",
        "            )\n",
        "        else:\n",
        "            self.residual_conv = nn.Identity()\n",
        "\n",
        "        self.relu = nn.SiLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.residual_conv(x)\n",
        "        out = self.block(x)\n",
        "        return self.relu(out + identity)\n",
        "\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.rc1 = ResidualConv(\n",
        "            in_channels=self.in_channels,\n",
        "            out_channels=256\n",
        "        )\n",
        "        self.rc2 = ResidualConv(\n",
        "            in_channels=256,\n",
        "            out_channels=256\n",
        "        )\n",
        "        self.rc3 = ResidualConv(\n",
        "            in_channels=256,\n",
        "            out_channels=256\n",
        "        )\n",
        "        self.rc4 = ResidualConv(\n",
        "            in_channels=256,\n",
        "            out_channels=512\n",
        "        )\n",
        "        self.rc5 = ResidualConv(\n",
        "            in_channels=512,\n",
        "            out_channels=512\n",
        "        )\n",
        "        self.rc6 = ResidualConv(\n",
        "            in_channels=512,\n",
        "            out_channels=512\n",
        "        )\n",
        "        self.rc7 = ResidualConv(\n",
        "            in_channels=512,\n",
        "            out_channels=self.out_channels\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.rc1(x)\n",
        "        x = self.rc2(x)\n",
        "        x = self.rc3(x)\n",
        "        x = self.rc4(x)\n",
        "        x = self.rc5(x)\n",
        "        x = self.rc6(x)\n",
        "        x = self.rc7(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udjZU8oZS2fz"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghFZqujLS5DS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import lightning as L\n",
        "\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HomomorphicUnet(nn.Module):\n",
        "    def __init__(self, image_size, in_channels, out_channels, offset, init_cutoff):\n",
        "        super().__init__()\n",
        "        self.image_size = image_size\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.offset = offset\n",
        "        self.init_cutoff = init_cutoff\n",
        "\n",
        "        self.rgb2ycrcb = RGB2YCrCb(\n",
        "            offset=self.offset\n",
        "        )\n",
        "        self.homo_separate = HomomorphicSeparation(\n",
        "            size=self.image_size,\n",
        "            init_cutoff=self.init_cutoff\n",
        "        )\n",
        "        self.unet = UNet(\n",
        "            in_channels=self.in_channels,\n",
        "            out_channels=self.out_channels\n",
        "        )\n",
        "        self.resnet = Resnet(\n",
        "            in_channels=self.in_channels,\n",
        "            out_channels=self.out_channels\n",
        "        )\n",
        "        self.ycrcb2rgb = YCrCb2RGB(\n",
        "            offset=self.offset\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        Y, Cr, Cb = self.rgb2ycrcb(x)\n",
        "        x_i, x_d = self.homo_separate(Y)\n",
        "        n_i = self.unet(x_i)\n",
        "        n_i = self.resnet(n_i)\n",
        "        n_Y = torch.clamp(input=n_i * x_d, min=0, max=1)\n",
        "        enh_img = self.ycrcb2rgb(n_Y, Cr, Cb)\n",
        "        return enh_img, n_i, x_i, x_d\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9STseQ2kMMm"
      },
      "source": [
        "## Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HomomorphicUnetLightning(L.LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(hparams)\n",
        "\n",
        "        self.model = HomomorphicUnet(\n",
        "            image_size=hparams['image_size'],\n",
        "            in_channels=hparams['in_channels'],\n",
        "            out_channels=hparams['out_channels'],\n",
        "            offset=hparams['offset'],\n",
        "            init_cutoff=hparams[\"init_cutoff\"],\n",
        "        )\n",
        "\n",
        "        self.spa_loss = L_spa()\n",
        "        self.col_loss = L_col()\n",
        "        self.exp_loss = L_exp()\n",
        "\n",
        "        self.lambda_spa = hparams[\"lambda_spa\"]\n",
        "        self.lambda_col = hparams[\"lambda_col\"]\n",
        "        self.lambda_exp = hparams[\"lambda_exp\"]\n",
        "\n",
        "        self.metric = ImageQualityMetrics(device=\"cuda\")\n",
        "        self.metric.eval()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x = batch.to(self.device)\n",
        "        enh_img, n_i, x_i, x_d = self(x)\n",
        "\n",
        "        loss_spa = self.lambda_spa * torch.mean(\n",
        "            input=self.spa_loss(enh_img, x)\n",
        "        )\n",
        "        loss_col = self.lambda_col * torch.mean(\n",
        "            input=self.col_loss(enh_img)\n",
        "        )\n",
        "        loss_exp = self.lambda_exp * torch.mean(\n",
        "            input=self.exp_loss(enh_img)\n",
        "        )\n",
        "\n",
        "        total = (\n",
        "            loss_spa +\n",
        "            loss_col +\n",
        "            loss_exp\n",
        "        )\n",
        "\n",
        "        self.log_dict(dictionary={\n",
        "            \"train/1_spa\": loss_spa,\n",
        "            \"train/2_col\": loss_col,\n",
        "            \"train/3_exp\": loss_exp,\n",
        "            \"train/4_tot\": total,\n",
        "        }, prog_bar=True)\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            self.logger.experiment.add_images(\n",
        "                \"train/1_input\",\n",
        "                x,\n",
        "                self.global_step\n",
        "            )\n",
        "            self.logger.experiment.add_images(\n",
        "                \"train/2_x_i\",\n",
        "                x_i,\n",
        "                self.global_step\n",
        "            )\n",
        "            self.logger.experiment.add_images(\n",
        "                \"train/3_x_d\",\n",
        "                x_d,\n",
        "                self.global_step\n",
        "            )\n",
        "            self.logger.experiment.add_images(\n",
        "                \"train/4_enh_img\",\n",
        "                enh_img,\n",
        "                self.global_step\n",
        "            )\n",
        "            self.logger.experiment.add_images(\n",
        "                \"train/5_n_i\",\n",
        "                n_i,\n",
        "                self.global_step\n",
        "            )\n",
        "        return total\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x = batch.to(self.device)\n",
        "        enh_img, n_i, x_i, x_d = self(x)\n",
        "\n",
        "        loss_spa = self.lambda_spa * torch.mean(\n",
        "            input=self.spa_loss(enh_img, x)\n",
        "        )\n",
        "        loss_col = self.lambda_col * torch.mean(\n",
        "            input=self.col_loss(enh_img)\n",
        "        )\n",
        "        loss_exp = self.lambda_exp * torch.mean(\n",
        "            input=self.exp_loss(enh_img)\n",
        "        )\n",
        "\n",
        "        total = (\n",
        "            loss_spa +\n",
        "            loss_col +\n",
        "            loss_exp\n",
        "        )\n",
        "\n",
        "        self.log_dict(dictionary={\n",
        "            \"valid/1_spa\": loss_spa,\n",
        "            \"valid/2_col\": loss_col,\n",
        "            \"valid/3_exp\": loss_exp,\n",
        "            \"valid/4_tot\": total,\n",
        "        }, prog_bar=True)\n",
        "        return total\n",
        "\n",
        "    def test_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        x = batch.to(self.device)\n",
        "        enh_img, n_i, x_i, x_d = self(x)\n",
        "\n",
        "        metrics = self.metric.full(preds=enh_img, targets=x)\n",
        "\n",
        "        self.log_dict(dictionary={\n",
        "            \"bench/1_PSNR\": metrics[\"PSNR\"],\n",
        "            \"bench/2_SSIM\": metrics[\"SSIM\"],\n",
        "            \"bench/3_LPIPS\": metrics[\"LPIPS\"],\n",
        "            \"bench/4_NIQE\": metrics[\"NIQE\"],\n",
        "            \"bench/5_BRISQUE\": metrics[\"BRISQUE\"],\n",
        "        }, prog_bar=True)\n",
        "        return metrics\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        x = batch.to(self.device)\n",
        "        enh_img, n_i, x_i, x_d = self(x)\n",
        "        return enh_img\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(\n",
        "            params=self.parameters(),\n",
        "            lr=self.hparams['lr'],\n",
        "            weight_decay=self.hparams['decay'],\n",
        "        )\n",
        "\n",
        "        scheduler = CosineAnnealingWarmRestarts(\n",
        "            optimizer=optimizer,\n",
        "            T_0=10,           # 첫 번째 주기의 epoch 수\n",
        "            T_mult=2,         # 이후 주기의 길이 배수\n",
        "            eta_min=1e-7      # 최소 learning rate\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": scheduler,\n",
        "                \"interval\": \"epoch\",   # 매 epoch마다 업데이트\n",
        "                \"frequency\": 1,\n",
        "            }\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrVAvx9ejOAe"
      },
      "source": [
        "# main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFm-FY4njQcg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## hparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfgkd1tmjOw4"
      },
      "outputs": [],
      "source": [
        "def get_hparams():\n",
        "    hparams = {\n",
        "        # 모델 구조\n",
        "        \"image_size\": 256,\n",
        "        \"in_channels\": 1,\n",
        "        \"out_channels\": 1,\n",
        "        \"offset\": 0.5,\n",
        "        \"init_cutoff\": 0.1,\n",
        "\n",
        "        # 손실 함수 가중치 (losses.py 기준)\n",
        "        \"lambda_col\": 10.0,\n",
        "        \"lambda_exp\": 1,\n",
        "        \"lambda_spa\": 100.0,\n",
        "\n",
        "        # 최적화 및 학습 설정\n",
        "        \"lr\": 1e-4,\n",
        "        \"decay\": 1e-5,\n",
        "        \"epochs\": 10,\n",
        "        \"batch_size\": 16,\n",
        "        \"seed\": 290,\n",
        "\n",
        "        # 데이터 경로\n",
        "        \"train_data_path\": \"data/1_train\",\n",
        "        \"valid_data_path\": \"data/2_valid\",\n",
        "        \"bench_data_path\": \"data/3_bench\",\n",
        "        \"infer_data_path\": \"data/4_infer\",\n",
        "\n",
        "        # 로깅 설정\n",
        "        \"log_dir\": \"./runs/HomomorphicUResnet\",\n",
        "        \"experiment_name\": \"cutoff_parameter\",\n",
        "        \"inference\": \"inference\",\n",
        "        \"benchmark\": \"benchmark\",\n",
        "    }\n",
        "    return hparams\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siMqkaqnj0Yr"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    global hparams, model_class, lightning_trainer\n",
        "\n",
        "    model_class = HomomorphicUnetLightning\n",
        "    hparams = get_hparams()\n",
        "\n",
        "    print(\"[RUNNING] Trainer...\")\n",
        "    trainer = LightningTrainer(\n",
        "        model=model_class(hparams=hparams),\n",
        "        hparams=hparams\n",
        "    )\n",
        "    lightning_trainer = trainer.trainer\n",
        "    trainer.run()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udr-tckWj2Ej"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[RUNNING] Trainer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/user/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "Seed set to 290\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Start Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name     </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
              "┡━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model    │ HomomorphicUnet     │ 47.2 M │ train │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ spa_loss │ L_spa               │     36 │ train │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ col_loss │ L_col               │      0 │ train │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ exp_loss │ L_exp               │      0 │ train │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ metric   │ ImageQualityMetrics │  724 K │ eval  │\n",
              "└───┴──────────┴─────────────────────┴────────┴───────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType               \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
              "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model    │ HomomorphicUnet     │ 47.2 M │ train │\n",
              "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ spa_loss │ L_spa               │     36 │ train │\n",
              "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ col_loss │ L_col               │      0 │ train │\n",
              "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ exp_loss │ L_exp               │      0 │ train │\n",
              "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ metric   │ ImageQualityMetrics │  724 K │ eval  │\n",
              "└───┴──────────┴─────────────────────┴────────┴───────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 47.2 M                                                                                           \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 724 K                                                                                        \n",
              "<span style=\"font-weight: bold\">Total params</span>: 47.9 M                                                                                               \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 191                                                                        \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 187                                                                                         \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 105                                                                                          \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 47.2 M                                                                                           \n",
              "\u001b[1mNon-trainable params\u001b[0m: 724 K                                                                                        \n",
              "\u001b[1mTotal params\u001b[0m: 47.9 M                                                                                               \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 191                                                                        \n",
              "\u001b[1mModules in train mode\u001b[0m: 187                                                                                         \n",
              "\u001b[1mModules in eval mode\u001b[0m: 105                                                                                          \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ce24de2ea064bc29598b115c9af93a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "RuntimeError",
          "evalue": "NVML_SUCCESS == DriverAPI::get()->nvmlInit_v2_() INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":983, please report a bug to PyTorch. ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[29], line 13\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m trainer \u001b[38;5;241m=\u001b[39m LightningTrainer(\n\u001b[1;32m      9\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_class(hparams\u001b[38;5;241m=\u001b[39mhparams),\n\u001b[1;32m     10\u001b[0m     hparams\u001b[38;5;241m=\u001b[39mhparams\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m lightning_trainer \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[11], line 79\u001b[0m, in \u001b[0;36mLightningTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Start Training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatamodule\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Training Completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     51\u001b[0m     _call_teardown_hook(trainer)\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    592\u001b[0m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1056\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:320\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:192\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         closure()\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:270\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:176\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    179\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/core/module.py:1302\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1273\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1277\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \n\u001b[1;32m   1301\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1302\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:154\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision.py:123\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:140\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    139\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/torch/optim/adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 223\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    226\u001b[0m     params_with_grad: List[Tensor] \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision.py:109\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     98\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m     optimizer: Steppable,\n\u001b[1;32m    100\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m    101\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    hook is called.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:146\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:131\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 131\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:319\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual train step with the tied hooks.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[0;32m--> 319\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training_step_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mworld_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:328\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 328\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    331\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:391\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[26], line 30\u001b[0m, in \u001b[0;36mHomomorphicUnetLightning.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m     29\u001b[0m     x \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 30\u001b[0m     enh_img, n_i, x_i, x_d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     loss_spa \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_spa \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspa_loss(enh_img, x)\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     35\u001b[0m     loss_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_col \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_loss(enh_img)\n\u001b[1;32m     37\u001b[0m     )\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[26], line 26\u001b[0m, in \u001b[0;36mHomomorphicUnetLightning.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[25], line 33\u001b[0m, in \u001b[0;36mHomomorphicUnet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m x_i, x_d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhomo_separate(Y)\n\u001b[1;32m     32\u001b[0m n_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munet(x_i)\n\u001b[0;32m---> 33\u001b[0m n_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_i\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m n_Y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mn_i \u001b[38;5;241m*\u001b[39m x_d, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     35\u001b[0m enh_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mycrcb2rgb(n_Y, Cr, Cb)\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[23], line 81\u001b[0m, in \u001b[0;36mResnet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrc2(x)\n\u001b[1;32m     80\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrc3(x)\n\u001b[0;32m---> 81\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrc4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrc5(x)\n\u001b[1;32m     83\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrc6(x)\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/jih_icicic/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[23], line 39\u001b[0m, in \u001b[0;36mResidualConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual_conv(x)\n\u001b[1;32m     38\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock(x)\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43midentity\u001b[49m)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: NVML_SUCCESS == DriverAPI::get()->nvmlInit_v2_() INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":983, please report a bug to PyTorch. "
          ]
        }
      ],
      "source": [
        "main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[RUNNING] Inferencer...\n",
            "save_dir: runs/HomomorphicUnet/base/version_0/inference\n",
            "[INFO] Start training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Restoring states from the checkpoint path at runs/HomomorphicUnet/base/version_0/checkpoints/best-epoch=03.ckpt\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
            "Loaded model weights from the checkpoint at runs/HomomorphicUnet/base/version_0/checkpoints/best-epoch=03.ckpt\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c98e4a48aa540c68f029335d92fb5b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Inference completed.\n"
          ]
        }
      ],
      "source": [
        "path = Path(f\"{lightning_trainer.log_dir}\")\n",
        "ckpts = path.glob(pattern=\"checkpoints/best*.ckpt\")\n",
        "hparams = path.glob(pattern=\"hparams.yaml\")\n",
        "\n",
        "for ckpt, hparam in zip(ckpts, hparams):\n",
        "    print(\"[RUNNING] Inferencer...\")\n",
        "    inferencer = LightningInferencer(\n",
        "        model=model_class,\n",
        "        trainer=lightning_trainer,\n",
        "        ckpt=ckpt,\n",
        "        hparams=hparam,\n",
        "    )\n",
        "    inferencer.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for ckpt, hparam in zip(ckpts, hparams):\n",
        "    print(\"[RUNNING] Inferencer...\")\n",
        "    inferencer = LightningBenchmarker(\n",
        "        model=model_class,\n",
        "        trainer=lightning_trainer,\n",
        "        ckpt=ckpt,\n",
        "        hparams=hparam,\n",
        "    )\n",
        "    inferencer.run()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "jih_icicic",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
