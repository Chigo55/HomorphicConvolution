{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MMjHsM9TSmW"
      },
      "source": [
        "# data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49VIe1sP2LmK"
      },
      "source": [
        "## dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXEhB-oDxf-p"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yrm7XFBxebN"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, path, transform):\n",
        "        super().__init__()\n",
        "        self.path = Path(path)\n",
        "        self.transform = transform\n",
        "        self.data = list(self.path.rglob(pattern='*.*'))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = Image.open(fp=self.data[index]).convert(mode=\"RGB\")\n",
        "        return self.transform(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zyQLQwhs7EV"
      },
      "outputs": [],
      "source": [
        "class CustomDataModule(L.LightningDataModule):\n",
        "    def __init__(self, train_dir, valid_dir, infer_dir, bench_dir, transform, batch_size=32, num_workers=4):\n",
        "        super().__init__()\n",
        "        self.train_dir = Path(train_dir)\n",
        "        self.valid_dir = Path(valid_dir)\n",
        "        self.infer_dir = Path(infer_dir)\n",
        "        self.bench_dir = Path(bench_dir)\n",
        "\n",
        "        self.transform = transform\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_datasets = self._set_dataset(path=self.train_dir)\n",
        "        self.valid_datasets = self._set_dataset(path=self.valid_dir)\n",
        "        self.bench_datasets = self._set_dataset(path=self.bench_dir)\n",
        "        self.infer_datasets = self._set_dataset(path=self.infer_dir)\n",
        "\n",
        "    def _set_dataset(self, path):\n",
        "        datasets = []\n",
        "        for folder in path.iterdir():\n",
        "            if folder.is_dir():\n",
        "                datasets.append(\n",
        "                    CustomDataset(\n",
        "                        path=folder,\n",
        "                        transform=self.transform\n",
        "                    )\n",
        "                )\n",
        "        return datasets\n",
        "\n",
        "    def _set_dataloader(self, datasets, concat=False, shuffle=False):\n",
        "        if concat:\n",
        "            dataloader = DataLoader(\n",
        "                dataset=ConcatDataset(datasets=datasets),\n",
        "                batch_size=self.batch_size,\n",
        "                shuffle=shuffle,\n",
        "                num_workers=self.num_workers,\n",
        "                pin_memory=True\n",
        "            )\n",
        "            return dataloader\n",
        "        else:\n",
        "            dataloaders = []\n",
        "            for dataset in datasets:\n",
        "                loader = DataLoader(\n",
        "                    dataset=dataset,\n",
        "                    batch_size=self.batch_size,\n",
        "                    shuffle=shuffle,\n",
        "                    num_workers=self.num_workers,\n",
        "                    pin_memory=True\n",
        "                )\n",
        "                dataloaders.append(loader)\n",
        "            return dataloaders\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self._set_dataloader(datasets=self.train_datasets, concat=True, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self._set_dataloader(datasets=self.valid_datasets, concat=True)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self._set_dataloader(datasets=self.bench_datasets)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        return self._set_dataloader(datasets=self.infer_datasets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-ofYHcU2P4U"
      },
      "source": [
        "## utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uohVFoIuyKbK"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yz-ob2QEyGx-"
      },
      "outputs": [],
      "source": [
        "class DataTransform:\n",
        "    def __init__(self, image_size=256):\n",
        "        self.image_size = image_size\n",
        "\n",
        "        self.transform = self._build_transform()\n",
        "\n",
        "    def _build_transform(self):\n",
        "        base = [\n",
        "            transforms.Resize(size=(self.image_size, self.image_size)),\n",
        "            transforms.ToTensor(),\n",
        "        ]\n",
        "\n",
        "        return transforms.Compose(transforms=base)\n",
        "\n",
        "    def __call__(self, image):\n",
        "        return self.transform(img=image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from scipy.ndimage import convolve\n",
        "from scipy.special import gamma\n",
        "from torchmetrics.image import (\n",
        "    PeakSignalNoiseRatio,\n",
        "    StructuralSimilarityIndexMeasure,\n",
        "    LearnedPerceptualImagePatchSimilarity,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImageQualityMetrics(nn.Module):\n",
        "    def __init__(self, device=\"cuda\", data_range=1.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device_type = device\n",
        "\n",
        "        # reference-based metrics\n",
        "        self.psnr = PeakSignalNoiseRatio(\n",
        "            data_range=data_range).to(device=device)\n",
        "        self.ssim = StructuralSimilarityIndexMeasure(\n",
        "            data_range=data_range).to(device=device)\n",
        "        self.lpips = LearnedPerceptualImagePatchSimilarity(\n",
        "            net_type='squeeze').to(device=device)\n",
        "\n",
        "        # for NIQE (dummy pristine dist)\n",
        "        self.niqe_stats = np.load(\n",
        "            file=\"utils/files/niqe_params.npz\", allow_pickle=True)\n",
        "        self.mu_pris_param = self.niqe_stats['mu_pris_param']\n",
        "        self.cov_pris_param = self.niqe_stats['cov_pris_param']\n",
        "        self.gaussian_window = self.niqe_stats['gaussian_window']\n",
        "\n",
        "    def forward(self, preds: torch.Tensor, targets: torch.Tensor):\n",
        "        preds = preds.to(device=self.device_type)\n",
        "        targets = targets.to(device=self.device_type)\n",
        "\n",
        "        return {\n",
        "            \"PSNR\": self.psnr(preds, targets).item(),\n",
        "            \"SSIM\": self.ssim(preds, targets).item(),\n",
        "            \"LPIPS\": self.lpips(preds, targets).squeeze().mean().item(),\n",
        "        }\n",
        "\n",
        "    def no_ref(self, preds: torch.Tensor):\n",
        "        preds = preds.to(device=self.device_type)\n",
        "        preds_np = preds.detach().cpu().numpy()\n",
        "        preds_np = np.clip(a=preds_np, a_min=0, a_max=1)\n",
        "\n",
        "        niqe_list = []\n",
        "        brisque_list = []\n",
        "\n",
        "        for img in preds_np:\n",
        "            # (C, H, W) → (H, W, C)\n",
        "            img_np = np.transpose(a=img, axes=(1, 2, 0))\n",
        "            img_np_uint8 = (img_np * 255).astype(dtype=np.uint8)\n",
        "\n",
        "            niqe = self._compute_niqe(img_np=img_np)\n",
        "            brisuqe = self._compute_brisque(img=img_np_uint8)\n",
        "\n",
        "            niqe_list.append(niqe)\n",
        "            brisque_list.append(brisuqe)\n",
        "\n",
        "        return {\n",
        "            \"NIQE\": float(x=np.mean(a=niqe_list)),\n",
        "            \"BRISQUE\": float(x=np.mean(a=brisque_list)),\n",
        "        }\n",
        "\n",
        "    def full(self, preds, targets):\n",
        "        ref_metrics = self.forward(preds=preds, targets=targets)\n",
        "        no_ref_metrics = self.no_ref(preds=preds)\n",
        "        return {**ref_metrics, **no_ref_metrics}\n",
        "\n",
        "    # --------------------------\n",
        "    # Custom no-reference metrics\n",
        "    # --------------------------\n",
        "\n",
        "    def _compute_niqe(self, img_np):\n",
        "        img = img_np.astype(np.float32)\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        gray = gray.round()\n",
        "        return self._niqe(img=gray)\n",
        "\n",
        "    def _compute_brisque(self, img):\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        brisque_score = cv2.quality.QualityBRISQUE_compute(\n",
        "            img, \"utils/files/brisque_model.yaml\", \"utils/files/brisque_range.yaml\")\n",
        "        return brisque_score\n",
        "\n",
        "    def _niqe(self, img, block_size_h=96, block_size_w=96):\n",
        "        assert img.ndim == 2\n",
        "        h, w = img.shape\n",
        "        num_block_h = math.floor(h / block_size_h)\n",
        "        num_block_w = math.floor(w / block_size_w)\n",
        "        img = img[0:num_block_h * block_size_h, 0:num_block_w * block_size_w]\n",
        "\n",
        "        distparam = []\n",
        "        for scale in (1, 2):\n",
        "            mu = convolve(\n",
        "                input=img, weights=self.gaussian_window, mode='nearest')\n",
        "            sigma = np.sqrt(np.abs(convolve(\n",
        "                input=np.square(img), weights=self.gaussian_window, mode='nearest') - np.square(mu)))\n",
        "            img_nomalized = (img - mu) / (sigma + 1)\n",
        "\n",
        "            feat = []\n",
        "            for idx_w in range(num_block_w):\n",
        "                for idx_h in range(num_block_h):\n",
        "                    block = img_nomalized[\n",
        "                        idx_h * block_size_h // scale:(idx_h + 1) * block_size_h // scale,\n",
        "                        idx_w * block_size_w // scale:(idx_w + 1) * block_size_w // scale\n",
        "                    ]\n",
        "                    feat.append(self._compute_feature(block=block))\n",
        "\n",
        "            distparam.append(np.array(object=feat))\n",
        "\n",
        "            if scale == 1:\n",
        "                img = cv2.resize(img / 255., dsize=(0, 0), fx=0.5,\n",
        "                                 fy=0.5, interpolation=cv2.INTER_CUBIC) * 255.\n",
        "\n",
        "        distparam = np.concatenate(distparam, axis=1)\n",
        "        mu_distparam = np.nanmean(a=distparam, axis=0)\n",
        "        distparam_no_nan = distparam[~np.isnan(distparam).any(axis=1)]\n",
        "        cov_distparam = np.cov(m=distparam_no_nan, rowvar=False)\n",
        "\n",
        "        invcov_param = np.linalg.pinv(\n",
        "            (self.cov_pris_param + cov_distparam) / 2)\n",
        "        quality = np.matmul(\n",
        "            np.matmul((self.mu_pris_param - mu_distparam), invcov_param),\n",
        "            np.transpose(a=(self.mu_pris_param - mu_distparam))\n",
        "        )\n",
        "        return float(x=np.sqrt(quality))\n",
        "\n",
        "    def _compute_feature(self, block):\n",
        "        def estimate_aggd_param(block):\n",
        "            block = block.flatten()\n",
        "            gam = np.arange(start=0.2, stop=10.001, step=0.001)\n",
        "            gam_reciprocal = np.reciprocal(gam)\n",
        "            r_gam = np.square(gamma(gam_reciprocal * 2)) / (\n",
        "                gamma(gam_reciprocal) * gamma(gam_reciprocal * 3))\n",
        "\n",
        "            left_std = np.sqrt(np.mean(block[block < 0]**2))\n",
        "            right_std = np.sqrt(np.mean(block[block > 0]**2))\n",
        "            gammahat = left_std / right_std\n",
        "            rhat = (np.mean(np.abs(block)))**2 / np.mean(block**2)\n",
        "            rhatnorm = (rhat * (gammahat**3 + 1) *\n",
        "                        (gammahat + 1)) / ((gammahat**2 + 1)**2)\n",
        "            array_position = np.argmin(a=(r_gam - rhatnorm)**2)\n",
        "            alpha = gam[array_position]\n",
        "            beta_l = left_std * np.sqrt(gamma(1 / alpha) / gamma(3 / alpha))\n",
        "            beta_r = right_std * np.sqrt(gamma(1 / alpha) / gamma(3 / alpha))\n",
        "            return (alpha, beta_l, beta_r)\n",
        "\n",
        "        feat = []\n",
        "        alpha, beta_l, beta_r = estimate_aggd_param(block=block)\n",
        "        feat.extend([alpha, (beta_l + beta_r) / 2])\n",
        "        shifts = [[0, 1], [1, 0], [1, 1], [1, -1]]\n",
        "        for shift in shifts:\n",
        "            shifted = np.roll(a=block, shift=shift, axis=(0, 1))\n",
        "            alpha, beta_l, beta_r = estimate_aggd_param(block=block * shifted)\n",
        "            mean = (beta_r - beta_l) * (gamma(2 / alpha) / gamma(1 / alpha))\n",
        "            feat.extend([alpha, mean, beta_l, beta_r])\n",
        "        return feat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from torchvision.utils import save_image\n",
        "from torchinfo import summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_dirs(path: str | Path):\n",
        "    path = Path(path)\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "    return path\n",
        "\n",
        "\n",
        "def print_metrics(metrics: dict, prefix: str = \"\"):\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{prefix}{k}: {v:.4f}\")\n",
        "\n",
        "\n",
        "def save_images(results, save_dir, prefix=\"infer\", ext=\"png\"):\n",
        "    for i, datasets in enumerate(iterable=results):\n",
        "        save_path = make_dirs(path=f\"{save_dir}/batch{i+1}\")\n",
        "        for ii, batch in enumerate(iterable=datasets):\n",
        "            save_image(\n",
        "                tensor=batch,\n",
        "                fp=save_path / f\"{prefix}_{ii:04d}.{ext}\",\n",
        "                nrow=8,\n",
        "                padding=2,\n",
        "                normalize=True,\n",
        "                value_range=(0, 1)\n",
        "            )\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def summarize_model(model, input_size):\n",
        "    return summary(model=model, input_size=input_size, depth=3, col_names=[\"input_size\", \"output_size\", \"num_params\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lh4S0MOTaaJ"
      },
      "source": [
        "# engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA5HkZA-2VRM"
      },
      "source": [
        "## trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WA-AweC9yQbI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from lightning import Trainer, seed_everything\n",
        "from lightning.pytorch.callbacks import *\n",
        "from lightning.pytorch.loggers import TensorBoardLogger\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYf9FGjfyTUg"
      },
      "outputs": [],
      "source": [
        "class LightningTrainer:\n",
        "    def __init__(self, model, hparams: dict, ckpt: Path = None, transform=None):\n",
        "        self.hparams = hparams\n",
        "        self.transform = transform if transform else DataTransform()\n",
        "        seed_everything(seed=hparams[\"seed\"], workers=True)\n",
        "\n",
        "        # --- 모델 정의\n",
        "        if ckpt:\n",
        "            self.model = model.load_from_checkpoint(\n",
        "                checkpoint_path=ckpt,\n",
        "                map_location=\"cuda\",\n",
        "            )\n",
        "            self.ckpt = ckpt\n",
        "        else:\n",
        "            self.model = model\n",
        "\n",
        "        # --- DataModule 정의\n",
        "        self.datamodule = self._build_datamodule()\n",
        "\n",
        "        # --- 로깅 설정\n",
        "        self.logger = self._build_logger()\n",
        "\n",
        "        # --- 콜백 정의\n",
        "        self.callbacks = self._build_callbacks()\n",
        "\n",
        "        # --- Lightning Trainer 정의\n",
        "        self.trainer = Trainer(\n",
        "            max_epochs=hparams[\"epochs\"],\n",
        "            accelerator=\"gpu\",\n",
        "            devices=1,\n",
        "            precision=\"32\",\n",
        "            logger=self.logger,\n",
        "            callbacks=self.callbacks,\n",
        "            log_every_n_steps=5,\n",
        "        )\n",
        "\n",
        "    def _build_datamodule(self):\n",
        "        return CustomDataModule(\n",
        "            train_dir=self.hparams[\"train_data_path\"],\n",
        "            valid_dir=self.hparams[\"valid_data_path\"],\n",
        "            infer_dir=self.hparams[\"infer_data_path\"],\n",
        "            bench_dir=self.hparams[\"bench_data_path\"],\n",
        "            transform=DataTransform(image_size=self.hparams[\"image_size\"]),\n",
        "            batch_size=self.hparams[\"batch_size\"],\n",
        "            num_workers=int(os.cpu_count() * 0.9),\n",
        "        )\n",
        "\n",
        "    def _build_logger(self):\n",
        "        return TensorBoardLogger(\n",
        "            save_dir=self.hparams[\"log_dir\"],\n",
        "            name=self.hparams[\"experiment_name\"]\n",
        "        )\n",
        "\n",
        "    def _build_callbacks(self):\n",
        "        return [\n",
        "            ModelCheckpoint(\n",
        "                monitor=\"valid/4_tot\",\n",
        "                save_top_k=1,\n",
        "                mode=\"min\",\n",
        "                filename=\"best-{epoch:02d}\",\n",
        "            ),\n",
        "            ModelCheckpoint(\n",
        "                every_n_epochs=1,\n",
        "                save_top_k=-1,  # 모두 저장\n",
        "                filename=\"epoch-{epoch:02d}\",\n",
        "            ),\n",
        "            EarlyStopping(\n",
        "                monitor=\"valid/4_tot\",\n",
        "                patience=4,\n",
        "                mode=\"min\",\n",
        "                verbose=True,\n",
        "            ),\n",
        "            LearningRateMonitor(logging_interval=\"step\"),\n",
        "            RichProgressBar(),\n",
        "        ]\n",
        "\n",
        "    def run(self):\n",
        "        print(\"[INFO] Start Training...\")\n",
        "        self.trainer.fit(\n",
        "            model=self.model,\n",
        "            datamodule=self.datamodule\n",
        "        )\n",
        "        print(\"[INFO] Training Completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN4DsMQS2bfB"
      },
      "source": [
        "## validater"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TcPiApZ1EBm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from lightning import Trainer\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lxZzwSb0oM3"
      },
      "outputs": [],
      "source": [
        "class LightningValidater:\n",
        "    def __init__(self, model, trainer: Trainer, ckpt: Path, hparams: dict):\n",
        "        self.hparams = hparams\n",
        "\n",
        "        # --- 모델 정의\n",
        "        if ckpt:\n",
        "            self.model = model.load_from_checkpoint(\n",
        "                checkpoint_path=ckpt,\n",
        "                map_location=\"cuda\",\n",
        "            )\n",
        "            self.ckpt = ckpt\n",
        "        else:\n",
        "            self.model = model\n",
        "            self.ckpt = \"best\"\n",
        "\n",
        "        # --- Lightning Trainer 정의\n",
        "        self.trainer = trainer\n",
        "\n",
        "        # --- DataModule 정의\n",
        "        self.datamodule = self._build_datamodule()\n",
        "\n",
        "    def _build_datamodule(self):\n",
        "        return CustomDataModule(\n",
        "            train_dir=self.hparams[\"train_data_path\"],\n",
        "            valid_dir=self.hparams[\"valid_data_path\"],\n",
        "            infer_dir=self.hparams[\"infer_data_path\"],\n",
        "            bench_dir=self.hparams[\"bench_data_path\"],\n",
        "            transform=DataTransform(image_size=self.hparams[\"image_size\"]),\n",
        "            batch_size=self.hparams[\"batch_size\"],\n",
        "            num_workers=int(os.cpu_count() * 0.9),\n",
        "        )\n",
        "\n",
        "    def run(self):\n",
        "        print(\"[INFO] Start Validating...\")\n",
        "        results = self.trainer.validate(\n",
        "            model=self.model,\n",
        "            datamodule=self.datamodule,\n",
        "            ckpt_path=self.ckpt\n",
        "        )\n",
        "        print(\"[VALIDATION RESULT]\")\n",
        "        for res in tqdm(results):\n",
        "            print(res)\n",
        "\n",
        "        print(\"[INFO] Validation Completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-XEQ7Ab2g_L"
      },
      "source": [
        "## inferencer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_fzZBK51Hi5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "\n",
        "from lightning import Trainer\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Smv5YDwQ1I0U"
      },
      "outputs": [],
      "source": [
        "class LightningInferencer:\n",
        "    def __init__(self, model, trainer: Trainer, ckpt: Path, hparams: Path):\n",
        "        with open(file=hparams) as f:\n",
        "            hparams = yaml.load(stream=f, Loader=yaml.FullLoader)\n",
        "        self.hparams = hparams\n",
        "\n",
        "        if ckpt:\n",
        "            self.model = model.load_from_checkpoint(\n",
        "                checkpoint_path=str(object=ckpt),\n",
        "                map_location=\"cuda\",\n",
        "            )\n",
        "            self.ckpt = ckpt\n",
        "        else:\n",
        "            self.model = model\n",
        "            self.ckpt = \"best\"\n",
        "\n",
        "        # --- Lightning Trainer 정의\n",
        "        self.trainer = trainer\n",
        "\n",
        "        # --- DataModule 정의\n",
        "        self.datamodule = self._build_datamodule()\n",
        "\n",
        "        self.save_dir = ckpt.parents[1] / hparams[\"inference\"]\n",
        "        print(f\"save_dir: {self.save_dir}\")\n",
        "\n",
        "    def _build_datamodule(self):\n",
        "        return CustomDataModule(\n",
        "            train_dir=self.hparams[\"train_data_path\"],\n",
        "            valid_dir=self.hparams[\"valid_data_path\"],\n",
        "            infer_dir=self.hparams[\"infer_data_path\"],\n",
        "            bench_dir=self.hparams[\"bench_data_path\"],\n",
        "            transform=DataTransform(image_size=self.hparams[\"image_size\"]),\n",
        "            batch_size=self.hparams[\"batch_size\"],\n",
        "            num_workers=int(os.cpu_count() * 0.9),\n",
        "        )\n",
        "\n",
        "    def run(self):\n",
        "        print(\"[INFO] Start Inferencing...\")\n",
        "        results = self.trainer.predict(\n",
        "            model=self.model,\n",
        "            datamodule=self.datamodule,\n",
        "            ckpt_path=self.ckpt\n",
        "        )\n",
        "        save_images(results=results, save_dir=self.save_dir)\n",
        "        print(\"[INFO] Inference Completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YobhDE1g2lC3"
      },
      "source": [
        "## benchmarker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_f7eA4M1P8Y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from lightning import Trainer\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCpVMRNi1Sjx"
      },
      "outputs": [],
      "source": [
        "class LightningBenchmarker:\n",
        "    def __init__(self, model, trainer: Trainer, ckpt: Path, hparams: dict):\n",
        "        self.hparams = hparams\n",
        "\n",
        "        if ckpt:\n",
        "            self.model = model.load_from_checkpoint(\n",
        "                checkpoint_path=ckpt,\n",
        "                map_location=\"cuda\",\n",
        "            )\n",
        "            self.ckpt = ckpt\n",
        "        else:\n",
        "            self.model = model\n",
        "            self.ckpt = \"best\"\n",
        "\n",
        "        # --- Lightning Trainer 정의\n",
        "        self.trainer = trainer\n",
        "\n",
        "        # --- DataModule 정의\n",
        "        self.datamodule = self._build_datamodule()\n",
        "\n",
        "        self.save_dir = ckpt.parents[1] / hparams[\"benchmark\"]\n",
        "        print(f\"save_dir: {self.save_dir}\")\n",
        "\n",
        "        # --- 평가 메트릭 정의\n",
        "        self.metric = ImageQualityMetrics(device=\"cuda\")\n",
        "        self.metric.eval()\n",
        "\n",
        "    def _build_datamodule(self):\n",
        "        datamodule = CustomDataModule(\n",
        "            train_dir=self.hparams[\"train_data_path\"],\n",
        "            valid_dir=self.hparams[\"valid_data_path\"],\n",
        "            infer_dir=self.hparams[\"infer_data_path\"],\n",
        "            bench_dir=self.hparams[\"bench_data_path\"],\n",
        "            transform=DataTransform(image_size=self.hparams[\"image_size\"]),\n",
        "            batch_size=self.hparams[\"batch_size\"],\n",
        "            num_workers=int(os.cpu_count() * 0.9),\n",
        "        )\n",
        "        datamodule.setup()  # 벤치마크 데이터셋 사용 위해 미리 세팅\n",
        "        return datamodule\n",
        "\n",
        "    def run(self):\n",
        "        print(\"[INFO] Start benchmarking\")\n",
        "\n",
        "        results = self.trainer.test(\n",
        "            model=self.model,\n",
        "            datamodule=self.datamodule,\n",
        "            ckpt_path=self.ckpt\n",
        "        )\n",
        "        print(\"results\", results)\n",
        "        print(\"\\n[FINAL BENCHMARK RESULT]\")\n",
        "        for i, datasets in tqdm(enumerate(iterable=results)):\n",
        "            for k, v in datasets.items():\n",
        "                print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "        save_images(results=results, save_dir=self.save_dir)\n",
        "        print(\"[INFO] Benchmark Completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QFt6KdDTjPW"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class L_col(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean_rgb = torch.mean(\n",
        "            input=x,\n",
        "            dim=[2, 3],\n",
        "            keepdim=True\n",
        "        )\n",
        "        mr, mg, mb = torch.split(\n",
        "            tensor=mean_rgb,\n",
        "            split_size_or_sections=1,\n",
        "            dim=1\n",
        "        )\n",
        "\n",
        "        Drg = torch.pow(input=mr - mg, exponent=2)\n",
        "        Drb = torch.pow(input=mr - mb, exponent=2)\n",
        "        Dgb = torch.pow(input=mb - mg, exponent=2)\n",
        "\n",
        "        c = torch.pow(\n",
        "            input=torch.pow(input=Drg, exponent=2) +\n",
        "            torch.pow(input=Drb, exponent=2) +\n",
        "            torch.pow(input=Dgb, exponent=2),\n",
        "            exponent=0.5\n",
        "        )\n",
        "        return c\n",
        "\n",
        "\n",
        "class L_spa(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        kernel_l = torch.FloatTensor([\n",
        "            [0, 0, 0],\n",
        "            [-1, 1, 0],\n",
        "            [0, 0, 0]\n",
        "        ]).cuda().unsqueeze(dim=0).unsqueeze(dim=0)\n",
        "        kernel_r = torch.FloatTensor([\n",
        "            [0, 0, 0],\n",
        "            [0, 1, -1],\n",
        "            [0, 0, 0]\n",
        "        ]).cuda().unsqueeze(dim=0).unsqueeze(dim=0)\n",
        "        kernel_u = torch.FloatTensor([\n",
        "            [0, -1, 0],\n",
        "            [0, 1, 0],\n",
        "            [0, 0, 0]\n",
        "        ]).cuda().unsqueeze(dim=0).unsqueeze(dim=0)\n",
        "        kernel_d = torch.FloatTensor([\n",
        "            [0, 0, 0],\n",
        "            [0, 1, 0],\n",
        "            [0, -1, 0]\n",
        "        ]).cuda().unsqueeze(dim=0).unsqueeze(dim=0)\n",
        "\n",
        "        self.weight_l = nn.Parameter(data=kernel_l, requires_grad=False)\n",
        "        self.weight_r = nn.Parameter(data=kernel_r, requires_grad=False)\n",
        "        self.weight_u = nn.Parameter(data=kernel_u, requires_grad=False)\n",
        "        self.weight_d = nn.Parameter(data=kernel_d, requires_grad=False)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=4)\n",
        "\n",
        "    def forward(self, org, enh):\n",
        "        org_mean = torch.mean(input=org, dim=1, keepdim=True)\n",
        "        enh_mean = torch.mean(input=enh, dim=1, keepdim=True)\n",
        "\n",
        "        org_pool = self.pool(org_mean)\n",
        "        enh_pool = self.pool(enh_mean)\n",
        "\n",
        "        D_org_l = F.conv2d(input=org_pool, weight=self.weight_l, padding=1)\n",
        "        D_org_r = F.conv2d(input=org_pool, weight=self.weight_r, padding=1)\n",
        "        D_org_u = F.conv2d(input=org_pool, weight=self.weight_u, padding=1)\n",
        "        D_org_d = F.conv2d(input=org_pool, weight=self.weight_d, padding=1)\n",
        "\n",
        "        D_enh_l = F.conv2d(input=enh_pool, weight=self.weight_l, padding=1)\n",
        "        D_enh_r = F.conv2d(input=enh_pool, weight=self.weight_r, padding=1)\n",
        "        D_enh_u = F.conv2d(input=enh_pool, weight=self.weight_u, padding=1)\n",
        "        D_enh_d = F.conv2d(input=enh_pool, weight=self.weight_d, padding=1)\n",
        "\n",
        "        D_l = torch.pow(input=D_org_l - D_enh_l, exponent=2)\n",
        "        D_r = torch.pow(input=D_org_r - D_enh_r, exponent=2)\n",
        "        D_u = torch.pow(input=D_org_u - D_enh_u, exponent=2)\n",
        "        D_d = torch.pow(input=D_org_d - D_enh_d, exponent=2)\n",
        "\n",
        "        s = (D_l + D_r + D_u + D_d)\n",
        "        return s\n",
        "\n",
        "\n",
        "class L_exp(nn.Module):\n",
        "    def __init__(self, patch_size=16, mean_val=0.8):\n",
        "        super().__init__()\n",
        "        self.pool = nn.AvgPool2d(kernel_size=patch_size)\n",
        "        self.mean_val = mean_val\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.mean(input=x, dim=1, keepdim=True)\n",
        "        mean = self.pool(x)\n",
        "\n",
        "        e = torch.mean(\n",
        "            input=torch.pow(\n",
        "                input=mean - torch.FloatTensor(\n",
        "                    [self.mean_val]\n",
        "                ).cuda(),\n",
        "                exponent=2\n",
        "            )\n",
        "        )\n",
        "        return e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQXFZQKy2pao"
      },
      "source": [
        "## block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV7wTXp52sq_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksWXAbzx25Pc"
      },
      "outputs": [],
      "source": [
        "class RGB2YCrCb(nn.Module):\n",
        "    def __init__(self, offset=0.5):\n",
        "        super().__init__()\n",
        "        self.offset = offset\n",
        "        self.register_buffer(\n",
        "            name='weights',\n",
        "            tensor=torch.tensor(\n",
        "                data=[\n",
        "                    [0.299,  0.587,  0.114],   # Y\n",
        "                    [0.713, -0.713,  0.000],   # Cr\n",
        "                    [0.000, -0.564,  0.564],   # Cb\n",
        "                ],\n",
        "                dtype=torch.float32\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.einsum('bchw,oc->bohw', x, self.weights)\n",
        "\n",
        "        Y = out[:, 0:1, :, :]  # (B,1,H,W)\n",
        "        Cr = out[:, 1:2, :, :] + self.offset  # (B,1,H,W)\n",
        "        Cb = out[:, 2:3, :, :] + self.offset  # (B,1,H,W)\n",
        "        return Y, Cr, Cb\n",
        "\n",
        "\n",
        "class YCrCb2RGB(nn.Module):\n",
        "    def __init__(self, offset=0.5,):\n",
        "        super().__init__()\n",
        "        self.offset = offset\n",
        "        self.register_buffer(\n",
        "            name='weights',\n",
        "            tensor=torch.tensor(\n",
        "                data=[\n",
        "                    [1.000, 1.403, 0.000],\n",
        "                    [1.000, -0.714, -0.344],\n",
        "                    [1.000, 0.000, 1.773]\n",
        "                ],\n",
        "                dtype=torch.float32\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def forward(self, Y, Cr, Cb):\n",
        "        Cr = Cr - self.offset\n",
        "        Cb = Cb - self.offset\n",
        "\n",
        "        inputs = torch.cat(tensors=[Y, Cr, Cb], dim=1)  # (B,3,H,W)\n",
        "\n",
        "        x = torch.einsum('bchw,oc->bohw', inputs, self.weights)\n",
        "        return x\n",
        "\n",
        "\n",
        "class HomomorphicSeparation(nn.Module):\n",
        "    def __init__(self, size=256, init_cutoff=0.1, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.eps = eps\n",
        "\n",
        "        init_p = float(init_cutoff)\n",
        "        raw_init = torch.log(input=torch.tensor(data=init_p / (1.0 - init_p)))\n",
        "        self.raw_cutoff = nn.Parameter(data=raw_init)\n",
        "\n",
        "        coord = torch.linspace(start=-1, end=1, steps=size)\n",
        "        y, x = torch.meshgrid(coord, coord, indexing='ij')\n",
        "        d = torch.sqrt(input=x**2 + y**2)  # (H, W)\n",
        "        self.register_buffer(name='d', tensor=d)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        cutoff = torch.sigmoid(input=self.raw_cutoff)\n",
        "\n",
        "        mask2d = torch.exp(input=-(self.d ** 2) / (2 * (cutoff ** 2)))\n",
        "        mask = mask2d.unsqueeze(dim=0).expand(B, H, W)\n",
        "\n",
        "        # 1. log 변환\n",
        "        x_log = torch.log(input=x + self.eps).squeeze(dim=1)    # (B, 1, H, W)\n",
        "\n",
        "        # 2. FFT\n",
        "        x_fft = torch.fft.fft2(x_log)  # (B, H, W)\n",
        "\n",
        "        # 3. Low-pass / High-pass 분리\n",
        "        low_fft = x_fft * mask\n",
        "        high_fft = x_fft * (1 - mask)\n",
        "\n",
        "        # 4. IFFT 후 real 값 추출\n",
        "        low_spatial = torch.real(\n",
        "            input=torch.fft.ifft2(\n",
        "                low_fft\n",
        "            )\n",
        "        )  # (B,1,H,W)\n",
        "        high_spatial = torch.real(\n",
        "            input=torch.fft.ifft2(\n",
        "                high_fft\n",
        "            )\n",
        "        )  # (B,1,H,W)\n",
        "\n",
        "        # 5. exp 복원\n",
        "        illumination = torch.exp(input=low_spatial).unsqueeze(dim=1)\n",
        "        detail = torch.exp(input=high_spatial).unsqueeze(dim=1)\n",
        "\n",
        "        return illumination, detail\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResidualConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.in_channels,\n",
        "                out_channels=self.out_channels,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=out_channels),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.out_channels,\n",
        "                out_channels=self.out_channels,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=out_channels),\n",
        "        )\n",
        "\n",
        "        if self.in_channels != self.out_channels:\n",
        "            self.residual_conv = nn.Conv2d(\n",
        "                in_channels=self.in_channels,\n",
        "                out_channels=self.out_channels,\n",
        "                kernel_size=1\n",
        "            )\n",
        "        else:\n",
        "            self.residual_conv = nn.Identity()\n",
        "\n",
        "        self.relu = nn.SiLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.residual_conv(x)\n",
        "        out = self.block(x)\n",
        "        return self.relu(out + identity)\n",
        "\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.rc1 = ResidualConv(\n",
        "            in_channels=self.in_channels,\n",
        "            out_channels=256\n",
        "        )\n",
        "        self.rc2 = ResidualConv(\n",
        "            in_channels=256,\n",
        "            out_channels=256\n",
        "        )\n",
        "        self.rc3 = ResidualConv(\n",
        "            in_channels=256,\n",
        "            out_channels=256\n",
        "        )\n",
        "        self.rc4 = ResidualConv(\n",
        "            in_channels=256,\n",
        "            out_channels=512\n",
        "        )\n",
        "        self.rc5 = ResidualConv(\n",
        "            in_channels=512,\n",
        "            out_channels=512\n",
        "        )\n",
        "        self.rc6 = ResidualConv(\n",
        "            in_channels=512,\n",
        "            out_channels=512\n",
        "        )\n",
        "        self.rc7 = ResidualConv(\n",
        "            in_channels=512,\n",
        "            out_channels=self.out_channels\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.rc1(x)\n",
        "        x = self.rc2(x)\n",
        "        x = self.rc3(x)\n",
        "        x = self.rc4(x)\n",
        "        x = self.rc5(x)\n",
        "        x = self.rc6(x)\n",
        "        x = self.rc7(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udjZU8oZS2fz"
      },
      "source": [
        "## model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghFZqujLS5DS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import lightning as L\n",
        "\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HomomorphicResnet(nn.Module):\n",
        "    def __init__(self, image_size, in_channels, out_channels, offset, init_cutoff):\n",
        "        super().__init__()\n",
        "        self.image_size = image_size\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.offset = offset\n",
        "        self.init_cutoff = init_cutoff\n",
        "\n",
        "        self.rgb2ycrcb = RGB2YCrCb(\n",
        "            offset=self.offset\n",
        "        )\n",
        "        self.homo_separate = HomomorphicSeparation(\n",
        "            size=self.image_size,\n",
        "            init_cutoff=self.init_cutoff\n",
        "        )\n",
        "        self.resnet = Resnet(\n",
        "            in_channels=self.in_channels,\n",
        "            out_channels=self.out_channels\n",
        "        )\n",
        "        self.ycrcb2rgb = YCrCb2RGB(\n",
        "            offset=self.offset\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        Y, Cr, Cb = self.rgb2ycrcb(x)\n",
        "        x_i, x_d = self.homo_separate(Y)\n",
        "        n_i = self.resnet(x_i)\n",
        "        n_Y = torch.clamp(input=n_i * x_d, min=0, max=1)\n",
        "        enh_img = self.ycrcb2rgb(n_Y, Cr, Cb)\n",
        "        return enh_img, n_i, x_i, x_d\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9STseQ2kMMm"
      },
      "source": [
        "## lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1m5ERhmkOy6"
      },
      "outputs": [],
      "source": [
        "class HomomorphicResnetLightning(L.LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(hparams)\n",
        "\n",
        "        self.model = HomomorphicResnet(\n",
        "            image_size=hparams['image_size'],\n",
        "            in_channels=hparams['in_channels'],\n",
        "            out_channels=hparams['out_channels'],\n",
        "            offset=hparams['offset'],\n",
        "            init_cutoff=hparams[\"init_cutoff\"],\n",
        "        )\n",
        "\n",
        "        self.spa_loss = L_spa()\n",
        "        self.col_loss = L_col()\n",
        "        self.exp_loss = L_exp()\n",
        "\n",
        "        self.lambda_spa = hparams[\"lambda_spa\"]\n",
        "        self.lambda_col = hparams[\"lambda_col\"]\n",
        "        self.lambda_exp = hparams[\"lambda_exp\"]\n",
        "\n",
        "        self.metric = ImageQualityMetrics(device=\"cuda\")\n",
        "        self.metric.eval()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x = batch.to(self.device)\n",
        "        enh_img, n_i, x_i, x_d = self(x)\n",
        "\n",
        "        loss_spa = self.lambda_spa * torch.mean(\n",
        "            input=self.spa_loss(enh_img, x)\n",
        "        )\n",
        "        loss_col = self.lambda_col * torch.mean(\n",
        "            input=self.col_loss(enh_img)\n",
        "        )\n",
        "        loss_exp = self.lambda_exp * torch.mean(\n",
        "            input=self.exp_loss(enh_img)\n",
        "        )\n",
        "\n",
        "        total = (\n",
        "            loss_spa +\n",
        "            loss_col +\n",
        "            loss_exp\n",
        "        )\n",
        "\n",
        "        self.log_dict(dictionary={\n",
        "            \"train/1_spa\": loss_spa,\n",
        "            \"train/2_col\": loss_col,\n",
        "            \"train/3_exp\": loss_exp,\n",
        "            \"train/4_tot\": total,\n",
        "        }, prog_bar=True)\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            self.logger.experiment.add_images(\n",
        "                \"train/1_input\",\n",
        "                x,\n",
        "                self.global_step\n",
        "            )\n",
        "            self.logger.experiment.add_images(\n",
        "                \"train/2_x_i\",\n",
        "                x_i,\n",
        "                self.global_step\n",
        "            )\n",
        "            self.logger.experiment.add_images(\n",
        "                \"train/3_x_d\",\n",
        "                x_d,\n",
        "                self.global_step\n",
        "            )\n",
        "            self.logger.experiment.add_images(\n",
        "                \"train/4_enh_img\",\n",
        "                enh_img,\n",
        "                self.global_step\n",
        "            )\n",
        "            self.logger.experiment.add_images(\n",
        "                \"train/5_n_i\",\n",
        "                n_i,\n",
        "                self.global_step\n",
        "            )\n",
        "        return total\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x = batch.to(self.device)\n",
        "        enh_img, n_i, x_i, x_d = self(x)\n",
        "\n",
        "        loss_spa = self.lambda_spa * torch.mean(\n",
        "            input=self.spa_loss(enh_img, x)\n",
        "        )\n",
        "        loss_col = self.lambda_col * torch.mean(\n",
        "            input=self.col_loss(enh_img)\n",
        "        )\n",
        "        loss_exp = self.lambda_exp * torch.mean(\n",
        "            input=self.exp_loss(enh_img)\n",
        "        )\n",
        "\n",
        "        total = (\n",
        "            loss_spa +\n",
        "            loss_col +\n",
        "            loss_exp\n",
        "        )\n",
        "\n",
        "        self.log_dict(dictionary={\n",
        "            \"valid/1_spa\": loss_spa,\n",
        "            \"valid/2_col\": loss_col,\n",
        "            \"valid/3_exp\": loss_exp,\n",
        "            \"valid/4_tot\": total,\n",
        "        }, prog_bar=True)\n",
        "        return total\n",
        "\n",
        "    def test_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        x = batch.to(self.device)\n",
        "        enh_img, n_i, x_i, x_d = self(x)\n",
        "\n",
        "        metrics = self.metric.full(preds=enh_img, targets=x)\n",
        "\n",
        "        self.log_dict(dictionary={\n",
        "            \"bench/1_PSNR\": metrics[\"PSNR\"],\n",
        "            \"bench/2_SSIM\": metrics[\"SSIM\"],\n",
        "            \"bench/3_LPIPS\": metrics[\"LPIPS\"],\n",
        "            \"bench/4_NIQE\": metrics[\"NIQE\"],\n",
        "            \"bench/5_BRISQUE\": metrics[\"BRISQUE\"],\n",
        "        }, prog_bar=True)\n",
        "        return metrics\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        x = batch.to(self.device)\n",
        "        enh_img, n_i, x_i, x_d = self(x)\n",
        "        return enh_img\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(\n",
        "            params=self.parameters(),\n",
        "            lr=self.hparams['lr'],\n",
        "            weight_decay=self.hparams['decay'],\n",
        "        )\n",
        "\n",
        "        scheduler = CosineAnnealingWarmRestarts(\n",
        "            optimizer=optimizer,\n",
        "            T_0=10,           # 첫 번째 주기의 epoch 수\n",
        "            T_mult=2,         # 이후 주기의 길이 배수\n",
        "            eta_min=1e-7      # 최소 learning rate\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": scheduler,\n",
        "                \"interval\": \"epoch\",   # 매 epoch마다 업데이트\n",
        "                \"frequency\": 1,\n",
        "            }\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrVAvx9ejOAe"
      },
      "source": [
        "# main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFm-FY4njQcg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## hparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfgkd1tmjOw4"
      },
      "outputs": [],
      "source": [
        "def get_hparams():\n",
        "    hparams = {\n",
        "        # 모델 구조\n",
        "        \"image_size\": 256,\n",
        "        \"in_channels\": 1,\n",
        "        \"out_channels\": 1,\n",
        "        \"offset\": 0.5,\n",
        "        \"init_cutoff\": 0.1,\n",
        "\n",
        "        # 손실 함수 가중치 (losses.py 기준)\n",
        "        \"lambda_col\": 10.0,\n",
        "        \"lambda_exp\": 1,\n",
        "        \"lambda_spa\": 100.0,\n",
        "\n",
        "        # 최적화 및 학습 설정\n",
        "        \"lr\": 1e-4,\n",
        "        \"decay\": 1e-5,\n",
        "        \"epochs\": 10,\n",
        "        \"batch_size\": 32,\n",
        "        \"seed\": random.randint(a=0, b=1000),\n",
        "\n",
        "        # 데이터 경로\n",
        "        \"train_data_path\": \"data/1_train\",\n",
        "        \"valid_data_path\": \"data/2_valid\",\n",
        "        \"bench_data_path\": \"data/3_bench\",\n",
        "        \"infer_data_path\": \"data/4_infer\",\n",
        "\n",
        "        # 로깅 설정\n",
        "        \"log_dir\": \"./runs/HomomorphicResnet\",\n",
        "        \"experiment_name\": \"resnet_256_512\",\n",
        "        \"inference\": \"inference\",\n",
        "        \"benchmark\": \"benchmark\",\n",
        "    }\n",
        "    return hparams\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siMqkaqnj0Yr"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    global hparams, model_class, lightning_trainer\n",
        "\n",
        "    model_class = HomomorphicResnetLightning\n",
        "    hparams = get_hparams()\n",
        "\n",
        "    print(\"[RUNNING] Trainer...\")\n",
        "    trainer = LightningTrainer(\n",
        "        model=model_class(hparams=hparams),\n",
        "        hparams=hparams\n",
        "    )\n",
        "    lightning_trainer = trainer.trainer\n",
        "    trainer.run()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udr-tckWj2Ej"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,0\"\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = Path(f\"{lightning_trainer.log_dir}\")\n",
        "ckpts = path.glob(pattern=\"checkpoints/best*.ckpt\")\n",
        "hparams = path.glob(pattern=\"hparams.yaml\")\n",
        "\n",
        "for ckpt, hparam in zip(ckpts, hparams):\n",
        "    print(\"[RUNNING] Inferencer...\")\n",
        "    inferencer = LightningInferencer(\n",
        "        model=model_class,\n",
        "        trainer=lightning_trainer,\n",
        "        ckpt=ckpt,\n",
        "        hparams=hparam,\n",
        "    )\n",
        "    inferencer.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for ckpt, hparam in zip(ckpts, hparams):\n",
        "    print(\"[RUNNING] Inferencer...\")\n",
        "    inferencer = LightningBenchmarker(\n",
        "        model=model_class,\n",
        "        trainer=lightning_trainer,\n",
        "        ckpt=ckpt,\n",
        "        hparams=hparam,\n",
        "    )\n",
        "    inferencer.run()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "jih_icicic",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
